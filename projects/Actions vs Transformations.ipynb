{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('kdd99').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kddDF = (spark.read\n",
    "           .option('inferScehma', 'True')\n",
    "           .option('header', 'True')\n",
    "           .csv('data/kdd.csv')\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- duration: string (nullable = true)\n",
      " |-- protocol_type: string (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- src_bytes: string (nullable = true)\n",
      " |-- dst_bytes: string (nullable = true)\n",
      " |-- land: string (nullable = true)\n",
      " |-- wrong_fragment: string (nullable = true)\n",
      " |-- urgent: string (nullable = true)\n",
      " |-- hot: string (nullable = true)\n",
      " |-- num_failed_logins: string (nullable = true)\n",
      " |-- logged_in: string (nullable = true)\n",
      " |-- num_compromised: string (nullable = true)\n",
      " |-- root_shell: string (nullable = true)\n",
      " |-- su_attempted: string (nullable = true)\n",
      " |-- num_root: string (nullable = true)\n",
      " |-- num_file_creations: string (nullable = true)\n",
      " |-- num_shells: string (nullable = true)\n",
      " |-- num_access_files: string (nullable = true)\n",
      " |-- num_outbound_cmds: string (nullable = true)\n",
      " |-- is_host_login: string (nullable = true)\n",
      " |-- is_guest_login: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      " |-- srv_count: string (nullable = true)\n",
      " |-- serror_rate: string (nullable = true)\n",
      " |-- srv_serror_rate: string (nullable = true)\n",
      " |-- rerror_rate: string (nullable = true)\n",
      " |-- srv_rerror_rate: string (nullable = true)\n",
      " |-- same_srv_rate: string (nullable = true)\n",
      " |-- diff_srv_rate: string (nullable = true)\n",
      " |-- srv_diff_host_rate: string (nullable = true)\n",
      " |-- dst_host_count: string (nullable = true)\n",
      " |-- dst_host_srv_count: string (nullable = true)\n",
      " |-- dst_host_same_srv_rate: string (nullable = true)\n",
      " |-- dst_host_diff_srv_rate: string (nullable = true)\n",
      " |-- dst_host_same_src_port_rate: string (nullable = true)\n",
      " |-- dst_host_srv_diff_host_rate: string (nullable = true)\n",
      " |-- dst_host_serror_rate: string (nullable = true)\n",
      " |-- dst_host_srv_serror_rate: string (nullable = true)\n",
      " |-- dst_host_rerror_rate: string (nullable = true)\n",
      " |-- dst_host_srv_rerror_rate: string (nullable = true)\n",
      " |-- attack_type: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(duration='0', protocol_type='tcp', service='http', flag='SF', src_bytes='215', dst_bytes='45076', land='0', wrong_fragment='0', urgent='0', hot='0', num_failed_logins='0', logged_in='1', num_compromised='0', root_shell='0', su_attempted='0', num_root='0', num_file_creations='0', num_shells='0', num_access_files='0', num_outbound_cmds='0', is_host_login='0', is_guest_login='0', count='1', srv_count='1', serror_rate='0.00', srv_serror_rate='0.00', rerror_rate='0.00', srv_rerror_rate='0.00', same_srv_rate='1.00', diff_srv_rate='0.00', srv_diff_host_rate='0.00', dst_host_count='0', dst_host_srv_count='0', dst_host_same_srv_rate='0.00', dst_host_diff_srv_rate='0.00', dst_host_same_src_port_rate='0.00', dst_host_srv_diff_host_rate='0.00', dst_host_serror_rate='0.00', dst_host_srv_serror_rate='0.00', dst_host_rerror_rate='0.00', dst_host_srv_rerror_rate='0.00', attack_type='normal')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kddDF.printSchema()\n",
    "kddDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|    attack_type|  count|\n",
      "+---------------+-------+\n",
      "|          smurf|2807886|\n",
      "|        neptune|1072017|\n",
      "|         normal| 972781|\n",
      "|          satan|  15892|\n",
      "|        ipsweep|  12481|\n",
      "|      portsweep|  10413|\n",
      "|           nmap|   2316|\n",
      "|           back|   2203|\n",
      "|    warezclient|   1020|\n",
      "|       teardrop|    979|\n",
      "|            pod|    264|\n",
      "|   guess_passwd|     53|\n",
      "|buffer_overflow|     30|\n",
      "|           land|     21|\n",
      "|    warezmaster|     20|\n",
      "|           imap|     12|\n",
      "|        rootkit|     10|\n",
      "|     loadmodule|      9|\n",
      "|      ftp_write|      8|\n",
      "|       multihop|      7|\n",
      "|            phf|      4|\n",
      "|           perl|      3|\n",
      "|            spy|      2|\n",
      "+---------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kddDF.groupBy('attack_type').count().orderBy(col('count').desc()).show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d2e599039c56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Matt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Nick'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mike'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmyDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmyDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "myDF = spark.createDataFrame([('Matt', 22),('Nick', 23),('Mike', 20)], ['name', 'age'])\n",
    "myDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|Matt| 23|\n",
      "|Nick| 24|\n",
      "|Mike| 21|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDF.rdd.map(lambda row: (row[0], row[1]+1)).toDF(['name', 'age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|Matt| 23|\n",
      "|Nick| 24|\n",
      "|Mike| 21|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myDF.withColumn('newage', col('age')+1).select('name', col('newage').alias('age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['spark', 'rdd', 'example'], ['sample', 'example']]\n",
      "['spark', 'rdd', 'example', 'sample', 'example']\n"
     ]
    }
   ],
   "source": [
    "data = spark.sparkContext.parallelize([\"spark rdd example\", \"sample example\"], 2)\n",
    "\n",
    "y = data.map(lambda x: x.split(' '))\n",
    "print(y.collect())\n",
    "\n",
    "y = data.flatMap(lambda x: x.split(' '))\n",
    "print(y.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'flatMap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2ef420aacf82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark/spark-current/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1301\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1302\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'flatMap'"
     ]
    }
   ],
   "source": [
    "myDF.flatMap('age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver-Side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worker-Side"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
