{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark session\n",
    "spark = SparkSession.builder.appName('spork').getOrCreate()\n",
    "\n",
    "# read in data file\n",
    "data = spark.read.csv('data/cruise_ship_info.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show schema and display the data\n",
    "data.printSchema()\n",
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|      Cruise_line|count|\n",
      "+-----------------+-----+\n",
      "|            Costa|   11|\n",
      "|              P&O|    6|\n",
      "|           Cunard|    3|\n",
      "|Regent_Seven_Seas|    5|\n",
      "|              MSC|    8|\n",
      "|         Carnival|   22|\n",
      "|          Crystal|    2|\n",
      "|           Orient|    1|\n",
      "|         Princess|   17|\n",
      "|        Silversea|    4|\n",
      "|         Seabourn|    3|\n",
      "| Holland_American|   14|\n",
      "|         Windstar|    3|\n",
      "|           Disney|    2|\n",
      "|        Norwegian|   13|\n",
      "|          Oceania|    3|\n",
      "|          Azamara|    2|\n",
      "|        Celebrity|   10|\n",
      "|             Star|    6|\n",
      "|  Royal_Caribbean|   23|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('Cruise_line').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0),\n",
       " Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, cruise_cat=16.0),\n",
       " Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7, cruise_cat=1.0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol='Cruise_line', outputCol=\"cruise_cat\")\n",
    "indexed_data = indexer.fit(data).transform(data)\n",
    "indexed_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|crew|\n",
      "+--------------------+----+\n",
      "|[16.0,6.0,30.2769...|3.55|\n",
      "|[16.0,6.0,30.2769...|3.55|\n",
      "|[1.0,26.0,47.262,...| 6.7|\n",
      "|[1.0,11.0,110.0,2...|19.1|\n",
      "|[1.0,17.0,101.353...|10.0|\n",
      "|[1.0,22.0,70.367,...| 9.2|\n",
      "|[1.0,15.0,70.367,...| 9.2|\n",
      "|[1.0,23.0,70.367,...| 9.2|\n",
      "|[1.0,19.0,70.367,...| 9.2|\n",
      "|[1.0,6.0,110.2389...|11.5|\n",
      "|[1.0,10.0,110.0,2...|11.6|\n",
      "|[1.0,28.0,46.052,...| 6.6|\n",
      "|[1.0,18.0,70.367,...| 9.2|\n",
      "|[1.0,17.0,70.367,...| 9.2|\n",
      "|[1.0,11.0,86.0,21...| 9.3|\n",
      "|[1.0,8.0,110.0,29...|11.6|\n",
      "|[1.0,9.0,88.5,21....|10.3|\n",
      "|[1.0,15.0,70.367,...| 9.2|\n",
      "|[1.0,12.0,88.5,21...| 9.3|\n",
      "|[1.0,20.0,70.367,...| 9.2|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(train_data.columns)\n",
    "\n",
    "# can only assemble numerical vals\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['cruise_cat', 'Age', 'Tonnage', 'passengers', 'length', 'cabins', 'passenger_density'],\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "# build up a vector assembled features object for building model\n",
    "data_with_features = assembler.transform(indexed_data)\n",
    "\n",
    "\n",
    "\n",
    "final_data = data_with_features.select('features', 'crew')\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:\t 158\n",
      "Train:\t 128\n",
      "Test:\t 30\n"
     ]
    }
   ],
   "source": [
    "# split the data into train and test sets\n",
    "train_data, test_data = final_data.randomSplit([0.8, 0.2])\n",
    "\n",
    "print(\"Total:\\t\", final_data.count())\n",
    "print(\"Train:\\t\", train_data.count())\n",
    "print(\"Test:\\t\", test_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a linearregression instance\n",
    "lr = LinearRegression(labelCol='crew')\n",
    "\n",
    "# build the model by fitting the training data with features col to the LR instance\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9657591984682782"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model against the training data with features col\n",
    "results = lr_model.evaluate(test_data)\n",
    "\n",
    "# show variance actual vs expected\n",
    "results.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
